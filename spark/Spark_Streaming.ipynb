{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Data from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/09 00:09:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkConsumer\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/kafka_checkpoint\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.confluent:kafka-spark_2.12:5.5.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_schema = StructType() \\\n",
    "    .add(\"channel_id\", StringType()) \\\n",
    "    .add(\"title\", StringType()) \\\n",
    "    .add(\"description\", StringType()) \\\n",
    "    .add(\"custom_url\", StringType()) \\\n",
    "    .add(\"published_at\", StringType()) \\\n",
    "    .add(\"country\", StringType()) \\\n",
    "    .add(\"subscriber_count\", IntegerType()) \\\n",
    "    .add(\"view_count\", IntegerType()) \\\n",
    "    .add(\"video_count\", IntegerType()) \\\n",
    "    .add(\"hidden_subscriber_count\", BooleanType()) \\\n",
    "    .add(\"high_thumbnail\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_schema = StructType() \\\n",
    "    .add(\"video_id\", StringType()) \\\n",
    "    .add(\"title\", StringType()) \\\n",
    "    .add(\"description\", StringType()) \\\n",
    "    .add(\"description_summary\", StringType()) \\\n",
    "    .add(\"channel_id\", StringType()) \\\n",
    "    .add(\"channel_title\", StringType()) \\\n",
    "    .add(\"published_at\", StringType()) \\\n",
    "    .add(\"published_year\", StringType()) \\\n",
    "    .add(\"view_count\", IntegerType()) \\\n",
    "    .add(\"like_count\", IntegerType()) \\\n",
    "    .add(\"comment_count\", IntegerType()) \\\n",
    "    .add(\"favorite_count\", IntegerType()) \\\n",
    "    .add(\"engagement_ratio\", IntegerType()) \\\n",
    "    .add(\"likes_per_view\", IntegerType()) \\\n",
    "    .add(\"comments_per_view\", IntegerType()) \\\n",
    "    .add(\"thumbnail_url\", StringType()) \\\n",
    "    .add(\"thumbnail_width\", IntegerType()) \\\n",
    "    .add(\"thumbnail_height\", IntegerType()) \\\n",
    "    .add(\"duration\", StringType()) \\\n",
    "    .add(\"definition\", StringType()) \\\n",
    "    .add(\"caption\", BooleanType()) \\\n",
    "    .add(\"licensed_content\", BooleanType()) \\\n",
    "    .add(\"tags\", StringType()) \\\n",
    "    .add(\"tag_count\", IntegerType()) \\\n",
    "    .add(\"category_id\", StringType()) \\\n",
    "    .add(\"live_broadcast_content\", StringType()) \\\n",
    "    .add(\"default_language\", StringType()) \\\n",
    "    .add(\"default_audio_language\", StringType()) \\\n",
    "    .add(\"privacy_status\", StringType()) \\\n",
    "    .add(\"upload_status\", StringType()) \\\n",
    "    .add(\"embeddable\", BooleanType()) \\\n",
    "    .add(\"made_for_kids\", BooleanType()) \\\n",
    "    .add(\"title_length\", IntegerType()) \\\n",
    "    .add(\"description_length\", IntegerType()) \\\n",
    "    .add(\"has_hashtags\", BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_schema = StructType() \\\n",
    "    .add(\"comment_id\", StringType()) \\\n",
    "    .add(\"video_id\", StringType()) \\\n",
    "    .add(\"author\", StringType()) \\\n",
    "    .add(\"content\", StringType()) \\\n",
    "    .add(\"published_at\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_schema = StructType() \\\n",
    "    .add(\"video_id\", StringType()) \\\n",
    "    .add(\"caption_id\", StringType()) \\\n",
    "    .add(\"language\", StringType()) \\\n",
    "    .add(\"caption_text\", StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_video_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"youtube_video_info\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "kafka_channel_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"youtube_channel_info\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "kafka_comment_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"youtube_comments\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "kafka_captions_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"youtube_captions\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/09 00:24:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "video_parsed_df = kafka_video_df \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), video_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "channel_parsed_df = kafka_channel_df \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), channel_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "comment_parsed_df = kafka_comment_df \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), comment_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "captions_parsed_df = kafka_captions_df \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), captions_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- description_summary: string (nullable = true)\n",
      " |-- channel_id: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- published_at: string (nullable = true)\n",
      " |-- published_year: string (nullable = true)\n",
      " |-- view_count: integer (nullable = true)\n",
      " |-- like_count: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- engagement_ratio: integer (nullable = true)\n",
      " |-- likes_per_view: integer (nullable = true)\n",
      " |-- comments_per_view: integer (nullable = true)\n",
      " |-- thumbnail_url: string (nullable = true)\n",
      " |-- thumbnail_width: integer (nullable = true)\n",
      " |-- thumbnail_height: integer (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      " |-- caption: boolean (nullable = true)\n",
      " |-- licensed_content: boolean (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- tag_count: integer (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- live_broadcast_content: string (nullable = true)\n",
      " |-- default_language: string (nullable = true)\n",
      " |-- default_audio_language: string (nullable = true)\n",
      " |-- privacy_status: string (nullable = true)\n",
      " |-- upload_status: string (nullable = true)\n",
      " |-- embeddable: boolean (nullable = true)\n",
      " |-- made_for_kids: boolean (nullable = true)\n",
      " |-- title_length: integer (nullable = true)\n",
      " |-- description_length: integer (nullable = true)\n",
      " |-- has_hashtags: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_parsed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- channel_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- custom_url: string (nullable = true)\n",
      " |-- published_at: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- subscriber_count: integer (nullable = true)\n",
      " |-- view_count: integer (nullable = true)\n",
      " |-- video_count: integer (nullable = true)\n",
      " |-- hidden_subscriber_count: boolean (nullable = true)\n",
      " |-- high_thumbnail: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_parsed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- comment_id: string (nullable = true)\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- published_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_parsed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- caption_id: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- caption_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "captions_parsed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/09 00:25:59 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/03/09 00:25:59 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+----------+----------+-------------+--------------+----------------+--------------+-----------------+--------------------+---------------+----------------+--------+----------+-------+----------------+--------------------+---------+-----------+----------------------+----------------+----------------------+--------------+-------------+----------+-------------+------------+------------------+------------+\n",
      "|   video_id|               title|         description| description_summary|          channel_id|       channel_title|        published_at|published_year|view_count|like_count|comment_count|favorite_count|engagement_ratio|likes_per_view|comments_per_view|       thumbnail_url|thumbnail_width|thumbnail_height|duration|definition|caption|licensed_content|                tags|tag_count|category_id|live_broadcast_content|default_language|default_audio_language|privacy_status|upload_status|embeddable|made_for_kids|title_length|description_length|has_hashtags|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+----------+----------+-------------+--------------+----------------+--------------+-----------------+--------------------+---------------+----------------+--------+----------+-------+----------------+--------------------+---------+-----------+----------------------+----------------+----------------------+--------------+-------------+----------+-------------+------------+------------------+------------+\n",
      "|rfscVS0vtbw|Learn Python - Fu...|This course will ...|This course will ...|UC8butISFwT-Wl7EV...|    freeCodeCamp.org|2018-07-11T18:00:42Z|          2018|  46163397|   1072515|        44993|             0|            NULL|          NULL|             NULL|https://i.ytimg.c...|           1280|             720|        |          |  false|           false|[\"python\",\"python...|       14|         27|                  none|              en|                    en|              |             |      true|        false|          51|              3739|        true|\n",
      "|HeQX2HjkcNo|Math's Fundamenta...|Not everything th...|Not everything th...|UCHnyfMqiRRG1u-2M...|          Veritasium|2021-05-22T14:23:50Z|          2021|  28603310|    742611|        49794|             0|            NULL|          NULL|             NULL|https://i.ytimg.c...|           1280|             720|        |          |  false|           false|[\"veritasium\",\"sc...|        3|         27|                  none|              en|                    en|              |             |      true|        false|          23|              3230|       false|\n",
      "|PmlRbfSavbI|Stealing Baseball...|I always sucked a...|I always sucked a...|UCY1kMZp36IQSyNx_...|          Mark Rober|2019-06-30T17:23:23Z|          2019|  28464186|    453906|        14052|             0|            NULL|          NULL|             NULL|https://i.ytimg.c...|           1280|             720|        |          |  false|           false|[\"mark rober\",\"ba...|       19|         28|                  none|              en|                    en|              |             |      true|        false|          55|              1744|        true|\n",
      "|UT2noVDFoaA|Help Protect the ...|We are excited to...|We are excited to...|UC0rqucBdTuFTjJie...|          TensorFlow|2021-11-22T20:01:21Z|          2021|  26013159|      1590|           37|             0|            NULL|          NULL|             NULL|https://i.ytimg.c...|           1280|             720|        |          |  false|           false|[\"Machine Learnin...|       11|         28|                  none|           en-US|                    en|              |             |      true|        false|          57|               412|       false|\n",
      "|49MwTFZV7Z4|Pinky and Panda F...|Pinky and Panda F...|Pinky and Panda F...|UCVZ6IwlLkrP6tFiO...|Pinky and Panda T...|2018-04-18T05:59:07Z|          2018|  22885690|         0|            0|             0|            NULL|          NULL|             NULL|https://i.ytimg.c...|           1280|             720|        |          |  false|           false|[\"fun play\",\"Toy ...|        8|         27|                  none|                |                      |              |             |      true|        false|          71|                71|       false|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+----------+----------+-------------+--------------+----------------+--------------+-----------------+--------------------+---------------+----------------+--------+----------+-------+----------------+--------------------+---------+-----------+----------------------+----------------+----------------------+--------------+-------------+----------+-------------+------------+------------------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_query = video_parsed_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "# Await termination for 10 seconds\n",
    "video_query.awaitTermination(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/09 00:26:13 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/03/09 00:26:13 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+----------------+----------+-----------+-----------------------+--------------------+\n",
      "|          channel_id|               title|         description|          custom_url|        published_at|country|subscriber_count|view_count|video_count|hidden_subscriber_count|      high_thumbnail|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+----------------+----------+-----------+-----------------------+--------------------+\n",
      "|UCY1kMZp36IQSyNx_...|          Mark Rober|Former NASA engin...|          @markrober|2011-10-20T06:17:58Z|     US|        65000000|      NULL|        199|                  false|https://yt3.ggpht...|\n",
      "|UCHnyfMqiRRG1u-2M...|          Veritasium|An element of tru...|         @veritasium|2010-07-21T07:18:02Z|     US|        17400000|      NULL|        431|                  false|https://yt3.ggpht...|\n",
      "|UC8butISFwT-Wl7EV...|    freeCodeCamp.org|Learn to code for...|       @freecodecamp|2014-12-16T21:18:48Z|     US|        10500000| 839961366|       1820|                  false|https://yt3.ggpht...|\n",
      "|UCVZ6IwlLkrP6tFiO...|Pinky and Panda T...|KIDS will Enjoy t...|@pinkyandpandatoystv|2016-12-18T11:28:00Z|     US|         1590000|1064176310|        214|                  false|https://yt3.ggpht...|\n",
      "|UC0rqucBdTuFTjJie...|          TensorFlow|Welcome to the of...|         @tensorflow|2017-12-22T18:07:53Z|    N/A|          612000| 123012194|        673|                  false|https://yt3.ggpht...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-------+----------------+----------+-----------+-----------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "channel_query = channel_parsed_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "channel_query.awaitTermination(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment_query = comment_parsed_df \\\n",
    "#     .writeStream \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .format(\"console\") \\\n",
    "#     .start()\n",
    "\n",
    "# comment_query.awaitTermination(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions_query = captions_parsed_df \\\n",
    "#     .writeStream \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .format(\"console\") \\\n",
    "#     .start()\n",
    "\n",
    "# captions_query.awaitTermination(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
